{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tables in the database: ['sqlite_sequence', 'directus_migrations', 'directus_folders', 'directus_relations', 'directus_files', 'directus_fields', 'directus_operations', 'directus_notifications', 'directus_translations', 'directus_shares', 'directus_versions', 'directus_revisions', 'directus_users', 'directus_extensions', 'directus_sessions', 'directus_webhooks', 'directus_settings', 'directus_policies', 'directus_permissions', 'directus_access', 'directus_collections', 'directus_dashboards', 'directus_flows', 'directus_panels', 'directus_presets', 'directus_roles', 'directus_comments', 'directus_activity', 'TheNobleQuran']\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "\n",
    "# Load the uploaded SQLite database\n",
    "db_path = \"../directus-quran/Quran_111.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Verify table names\n",
    "table_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = pd.read_sql_query(table_query, conn)\n",
    "\n",
    "# Debug: Print available tables\n",
    "print(\"Available tables in the database:\", tables[\"name\"].tolist())\n",
    "\n",
    "# Read the data only if the table exists\n",
    "if \"TheNobleQuran\" in tables[\"name\"].tolist():\n",
    "    query = \"\"\"\n",
    "    SELECT sura_no, sura_name_en, sura_name_roman, ayah_no_surah, ayah_no_quran, ayah_translation_en\n",
    "    FROM TheNobleQuran\n",
    "    ORDER BY sura_no, CAST(ayah_no_surah AS INTEGER)\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "elif not tables.empty:\n",
    "    conn.close()\n",
    "    raise ValueError(f\"Table 'TheNobleQuran' does not exist. Available tables: {tables['name'].tolist()}\")\n",
    "else:\n",
    "    conn.close()\n",
    "    raise ValueError(\"No tables exist in the database. Please check the database file.\")\n",
    "\n",
    "conn.close()\n",
    "\n",
    "# Group by surah and create .mdx content\n",
    "# Group by surah and create .mdx content\n",
    "mdx_files = {}\n",
    "for surah_no, group in df.groupby(\"sura_no\"):\n",
    "    surah_name_en = group[\"sura_name_en\"].iloc[0]\n",
    "    surah_name_roman = group[\"sura_name_roman\"].iloc[0]\n",
    "    \n",
    "    # Sort the group by verse number to ensure correct order\n",
    "    # group = group.sort_values('ayah_no_surah')\n",
    "    \n",
    "    # Create proper frontmatter with --- on separate lines\n",
    "    content = \"---\\n\"\n",
    "    content += f\"title: Surah {surah_no} - {surah_name_en} ({surah_name_roman})\\n\"\n",
    "    content += f\"description: Translation of Surah {surah_no} - {surah_name_en} ({surah_name_roman})\\n\"\n",
    "    content += \"---\\n\\n\"\n",
    "    \n",
    "    # Add heading and content\n",
    "    # content += f\"# Surah {surah_no}: {surah_name_en} ({surah_name_roman})\\n\\n\"\n",
    "    for _, row in group.iterrows():\n",
    "        content += f\"**{row['ayah_no_surah']}.** {row['ayah_translation_en']}\\n\\n\"\n",
    "    \n",
    "    # Pad surah number with leading zeros for correct sorting (e.g., 001, 002, ..., 114)\n",
    "    filename = f\"surah-{str(surah_no).zfill(3)}.mdx\"\n",
    "    mdx_files[filename] = content\n",
    "\n",
    "# Save .mdx files to a downloadable zip\n",
    "output_dir = Path(\"../astro-quran/src/content/docs/surahs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for filename, content in mdx_files.items():\n",
    "    with open(output_dir / filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "# Zip the output directory\n",
    "# import shutil\n",
    "# zip_path = \"./data/surah-mdx-files.zip\"\n",
    "# shutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', output_dir)\n",
    "\n",
    "# print(f\"Generated {len(mdx_files)} MDX files with verses in correct numerical order\")\n",
    "# zip_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d764cbe",
   "metadata": {},
   "source": [
    "##  quran_translations & quran_metadata Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57535035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tables in the database: ['quran_translations', 'quran_metadata', 'sqlite_stat1', 'sqlite_stat4']\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "\n",
    "# Load the uploaded SQLite database\n",
    "db_path = \"quran_translations.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Verify table names\n",
    "table_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = pd.read_sql_query(table_query, conn)\n",
    "\n",
    "# Debug: Print available tables\n",
    "print(\"Available tables in the database:\", tables[\"name\"].tolist())\n",
    "\n",
    "# Read the data only if the table exists\n",
    "if \"quran_metadata\" in tables[\"name\"].tolist():\n",
    "    query = \"\"\"\n",
    "    SELECT surah_no, surah_name_en, surah_name_roman, ayah_no_surah, ayah_no_quran, ayah_ar, ayah_en, list_of_words\n",
    "    FROM quran_metadata\n",
    "    ORDER BY surah_no, CAST(ayah_no_surah AS INTEGER)\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "elif not tables.empty:\n",
    "    conn.close()\n",
    "    raise ValueError(f\"Table 'quran_metadata' does not exist. Available tables: {tables['name'].tolist()}\")\n",
    "else:\n",
    "    conn.close()\n",
    "    raise ValueError(\"No tables exist in the database. Please check the database file.\")\n",
    "\n",
    "conn.close()\n",
    "\n",
    "# Group by surah and create .mdx content\n",
    "# Group by surah and create .mdx content\n",
    "mdx_files = {}\n",
    "for surah_no, group in df.groupby(\"surah_no\"):\n",
    "    surah_name_en = group[\"surah_name_en\"].iloc[0]\n",
    "    surah_name_roman = group[\"surah_name_roman\"].iloc[0]\n",
    "    \n",
    "    # Sort the group by verse number to ensure correct order\n",
    "    # group = group.sort_values('ayah_no_surah')\n",
    "    \n",
    "    # Create proper frontmatter with --- on separate lines\n",
    "    content = \"---\\n\"\n",
    "    content += f\"title: Surah {surah_no} - {surah_name_en} ({surah_name_roman})\\n\"\n",
    "    content += f\"description: Translation of Surah {surah_no} - {surah_name_en} ({surah_name_roman})\\n\"\n",
    "    content += \"---\\n\\n\"\n",
    "    content += 'import Aside from \"~/components/Aside.astro\"\\n\\n'\n",
    "    content += 'import \"~/styles/asides.css\"\\n\\n'\n",
    "\n",
    "    # Add heading and content\n",
    "    # content += f\"# Surah {surah_no}: {surah_name_en} ({surah_name_roman})\\n\\n\"\n",
    "    for _, row in group.iterrows():\n",
    "        content += f\"\"\"\n",
    "            <Aside type=\"quran\" title=\"{row['ayah_no_surah']}\">\n",
    "            {row['ayah_ar']}\n",
    "            </Aside>\n",
    "\n",
    "            <Aside type=\"reference\" title=\"{row['ayah_no_surah']}\">\n",
    "            {row['ayah_en']}\n",
    "            </Aside>\n",
    "\n",
    "        ---\n",
    "        \"\"\"\n",
    "\n",
    "    # Pad surah number with leading zeros for correct sorting (e.g., 001, 002, ..., 114)\n",
    "    filename = f\"surah-{str(surah_no).zfill(3)}.mdx\"\n",
    "    mdx_files[filename] = content\n",
    "\n",
    "# Save .mdx files to a downloadable zip\n",
    "# output_dir = Path(\"../astro-quran/src/content/docs/surahs\")\n",
    "output_dir = Path(\"./data/mdx_surahs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for filename, content in mdx_files.items():\n",
    "    with open(output_dir / filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "# Zip the output directory\n",
    "# import shutil\n",
    "# zip_path = \"./data/surah-mdx-files.zip\"\n",
    "# shutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', output_dir)\n",
    "\n",
    "# print(f\"Generated {len(mdx_files)} MDX files with verses in correct numerical order\")\n",
    "# zip_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d0730",
   "metadata": {},
   "source": [
    "## Add ayah_no_quran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d306473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to your SQLite database\n",
    "conn = sqlite3.connect('quran_translations1.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Step 1: Add the new column (e.g., \"seq_no\")\n",
    "cursor.execute(\"ALTER TABLE quran_translations ADD COLUMN ayah_no_quran INTEGER\")\n",
    "\n",
    "# Step 2: Fetch all rowids to assign sequence numbers\n",
    "cursor.execute(\"SELECT rowid FROM quran_translations\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Step 3: Update each row with sequential numbers\n",
    "for i, (rowid,) in enumerate(rows, start=1):\n",
    "    cursor.execute(\"UPDATE quran_translations SET ayah_no_quran = ? WHERE rowid = ?\", (i, rowid))\n",
    "\n",
    "# Save changes\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e1eb8b",
   "metadata": {},
   "source": [
    "## Translations in diff folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "\n",
    "# Define paths to both databases\n",
    "db_main_path = \"quran_translations.db\"\n",
    "db_trans_path = \"quran_translations1.db\"\n",
    "\n",
    "# Connect to both databases\n",
    "conn_main = sqlite3.connect(db_main_path)\n",
    "conn_trans = sqlite3.connect(db_trans_path)\n",
    "\n",
    "# Load main quran_metadata\n",
    "query_main = \"\"\"\n",
    "SELECT surah_no, surah_name_en, surah_name_roman, ayah_no_surah, ayah_no_quran, ayah_ar, ayah_en, list_of_words\n",
    "FROM quran_metadata\n",
    "ORDER BY surah_no, CAST(ayah_no_surah AS INTEGER)\n",
    "\"\"\"\n",
    "df_main = pd.read_sql_query(query_main, conn_main)\n",
    "\n",
    "# Load translation table from second DB\n",
    "query_trans = \"SELECT * FROM quran_translations\"\n",
    "df_trans = pd.read_sql_query(query_trans, conn_trans)\n",
    "\n",
    "# Close DB connections\n",
    "conn_main.close()\n",
    "conn_trans.close()\n",
    "\n",
    "# Merge both datasets on ayah_no_quran\n",
    "df_merged = pd.merge(df_main, df_trans, on=\"ayah_no_quran\", how=\"left\")\n",
    "\n",
    "# Get all translation language columns\n",
    "translation_columns = [\n",
    "    \"bangla_translation\", \"chinese_translation\", \"german_translation\", \"italian-piccardo_translation\",\n",
    "    \"japanese_translation\", \"malayalam_translation\", \"norwegian_translation\", \"persian_translation\",\n",
    "    \"portuguese_translation\", \"russian_translation\", \"turkish_translation\", \"urdu_translation\",\n",
    "    \"uzbek_translation\", \"english_translation\"\n",
    "]\n",
    "\n",
    "# Base output directory\n",
    "base_output_dir = Path(\"./data/mdx_translations\")\n",
    "base_output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Loop over each translation language\n",
    "for lang in translation_columns:\n",
    "    mdx_files = {}\n",
    "    for surah_no, group in df_merged.groupby(\"surah_no\"):\n",
    "        surah_name_en = group[\"surah_name_en\"].iloc[0]\n",
    "        surah_name_roman = group[\"surah_name_roman\"].iloc[0]\n",
    "\n",
    "        content = \"---\\n\"\n",
    "        content += f'title: Surah {surah_no} - {surah_name_en} ({surah_name_roman})  \\n'\n",
    "        content += f'description: Translation of Surah {surah_no} - {surah_name_en} ({surah_name_roman}) in {lang.replace(\"_translation\", \"\").capitalize()}\\n'\n",
    "        content += \"---\\n\\n\"\n",
    "        content += 'import Aside from \"~/components/Aside.astro\"\\n\\n'\n",
    "        content += 'import Spacer from \"~/components/Spacer.astro\"\\n\\n'\n",
    "        content += 'import \"~/styles/asides.css\"\\n\\n'\n",
    "        content += 'import VerseCard from \"~/components/VerseCard.astro\"\\n\\n'\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            translation = row.get(lang, \"\").strip()\n",
    "            if translation:\n",
    "                content += f\"\"\"\n",
    "    <VerseCard \n",
    "    verseNumber={{{row['ayah_no_surah']}}}\n",
    "    chapterNumber={{{row['surah_no']}}}\n",
    "    arabicText=\"{row['ayah_ar']}\"\n",
    "    translation=\"{translation}\"\n",
    "    transliteration=\"{row.get('transliteration', '')}\"\n",
    "    />\n",
    "    \n",
    "    <Spacer size=\"0.5rem\" />\n",
    "                \"\"\"\n",
    "\n",
    "        filename = f\"surah-{str(surah_no).zfill(3)}.mdx\"\n",
    "        mdx_files[filename] = content\n",
    "\n",
    "    # Write to folder per language\n",
    "    lang_dir = base_output_dir / lang.replace(\"_translation\", \"\") / \"surahs\"\n",
    "    lang_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for filename, content in mdx_files.items():\n",
    "        with open(lang_dir / filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4145ba3c",
   "metadata": {},
   "source": [
    "COPY ENGLISH TRANSLATION FROM METADTA TO QURAN TRANSLATIONS TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a10c21e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Column copied successfully.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Paths to the source and target databases\n",
    "db_main_path = \"quran_translations.db\"\n",
    "db_trans_path = \"quran_translations1.db\"\n",
    "\n",
    "# Connect to the source DB\n",
    "src_conn = sqlite3.connect(db_main_path)\n",
    "src_cursor = src_conn.cursor()\n",
    "\n",
    "# Connect to the destination DB\n",
    "dest_conn = sqlite3.connect(db_trans_path)\n",
    "dest_cursor = dest_conn.cursor()\n",
    "\n",
    "# Step 1: Read ayan_en from source DB\n",
    "src_cursor.execute(\"SELECT rowid, ayah_en FROM quran_metadata\")\n",
    "data = src_cursor.fetchall()\n",
    "\n",
    "# Step 2: Add new column to destination table if it doesn't exist\n",
    "try:\n",
    "    dest_cursor.execute(\"ALTER TABLE quran_translations ADD COLUMN english_translation TEXT\")\n",
    "except sqlite3.OperationalError as e:\n",
    "    if \"duplicate column name\" in str(e):\n",
    "        print(\"Column 'english_translation' already exists, continuing...\")\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Step 3: Update destination table row by row\n",
    "for rowid, english_text in data:\n",
    "    dest_cursor.execute(\n",
    "        \"UPDATE quran_translations SET english_translation = ? WHERE rowid = ?\",\n",
    "        (english_text, rowid)\n",
    "    )\n",
    "\n",
    "# Commit and close\n",
    "dest_conn.commit()\n",
    "src_conn.close()\n",
    "dest_conn.close()\n",
    "\n",
    "print(\"✅ Column copied successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
